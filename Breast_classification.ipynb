{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing all the libraries"
      ],
      "metadata": {
        "id": "YPa68nWkyuQE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DGbcrS6pC25f"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch\n",
        "from torchvision import models\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pdB\n",
        "from sklearn.metrics import roc_auc_score, auc, roc_curve\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from shutil import rmtree, copytree, copyfile\n",
        "import random\n",
        "import warnings\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model1-inception v3"
      ],
      "metadata": {
        "id": "XIdOPjaNy07q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionV3(nn.Module):\n",
        "  def __init__(self, num_classes = 2):\n",
        "    super(InceptionV3, self).__init__()\n",
        "    model = models.inception_v3(pretrained=True, aux_logits=False)\n",
        "    self.Conv2d_1a_3x3 = model.Conv2d_1a_3x3\n",
        "    self.Conv2d_2a_3x3 = model.Conv2d_2a_3x3\n",
        "    self.Conv2d_2b_3x3 = model.Conv2d_2b_3x3\n",
        "    self.Conv2d_3b_1x1 = model.Conv2d_3b_1x1\n",
        "    self.Conv2d_4a_3x3 = model.Conv2d_4a_3x3\n",
        "    self.Mixed_5b = model.Mixed_5b\n",
        "    self.Mixed_5c = model.Mixed_5c\n",
        "    self.Mixed_5d = model.Mixed_5d\n",
        "    self.Mixed_6a = model.Mixed_6a\n",
        "    self.Mixed_6b = model.Mixed_6b\n",
        "    self.Mixed_6c = model.Mixed_6c\n",
        "    self.Mixed_6d = model.Mixed_6d\n",
        "    self.Mixed_6e = model.Mixed_6e\n",
        "    self.Mixed_7a = model.Mixed_7a\n",
        "    self.Mixed_7b = model.Mixed_7b\n",
        "    self.Mixed_7c = model.Mixed_7c\n",
        "\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "    self.fc = nn.Linear(2048, num_classes)\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "  def forward(self, x):\n",
        "      features = None\n",
        "      x = nn.Upsample(size=(299, 299), mode='bilinear')(x)\n",
        "      x = self.Conv2d_1a_3x3(x)\n",
        "      x = self.Conv2d_2a_3x3(x)\n",
        "      x = self.Conv2d_2b_3x3(x)\n",
        "      x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "      x = self.Conv2d_3b_1x1(x)\n",
        "      x = self.Conv2d_4a_3x3(x)\n",
        "\n",
        "      x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "      x = self.Mixed_5b(x)\n",
        "      x = self.Mixed_5c(x)\n",
        "      x = self.Mixed_5d(x)\n",
        "\n",
        "      x = self.Mixed_6a(x)\n",
        "      x = self.Mixed_6b(x)\n",
        "      x = self.Mixed_6c(x)\n",
        "      x = self.Mixed_6d(x)\n",
        "      x = self.Mixed_6e(x)\n",
        "\n",
        "      # image region features\n",
        "      features = x\n",
        "\n",
        "      x = self.Mixed_7a(x)\n",
        "      x = self.Mixed_7b(x)\n",
        "      x = self.Mixed_7c(x)\n",
        "      x = self.avgpool(x)\n",
        "      x = self.dropout(x)\n",
        "      x = x.view(x.size(0), -1)\n",
        "\n",
        "      x = self.fc(x)\n",
        "      return x "
      ],
      "metadata": {
        "id": "e2w-xzSsE4XA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model2-ResNet34"
      ],
      "metadata": {
        "id": "pPkqobadzGi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Resnet34(nn.Module):\n",
        "  def __init__(self, num_classes = 2):\n",
        "    super(Resnet34, self).__init__()\n",
        "    model = models.resnet34(pretrained=True)\n",
        "    self.conv1 = model.conv1\n",
        "    self.bn1 = model.bn1\n",
        "    self.relu = model.relu\n",
        "    self.maxpool = model.maxpool\n",
        "    self.layer1 = model.layer1\n",
        "    self.layer2 = model.layer2\n",
        "    self.layer3 = model.layer3\n",
        "    self.layer4 = model.layer4\n",
        "    self.avgpool = model.avgpool\n",
        "    self.__in_features = model.fc.in_features\n",
        "    self.fc = nn.Linear(512, num_classes)\n",
        "    # self.softmax = nn.Softmax()\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.layer4(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc(x)\n",
        "    # x = self.softmax(x)\n",
        "    return x\n",
        "\n",
        "  def output_num(self):\n",
        "    return self.__in_features"
      ],
      "metadata": {
        "id": "MJtT2kTmNEFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model3-DenseNet121"
      ],
      "metadata": {
        "id": "tggKtKtby9P1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Densnet121(nn.Module):\n",
        "  def __init__(self, num_classes = 2):\n",
        "    super(Densnet121, self).__init__()\n",
        "    model = models.densenet121(pretrained=True)\n",
        "    self.features = model.features\n",
        "    self.fc = nn.Linear(1024, num_classes)\n",
        "    self.relu_out = 0\n",
        "\n",
        "  def forward(self, x):\n",
        "    features = self.features(x)\n",
        "    out = F.relu(features, inplace=True)\n",
        "    self.relu_out = out\n",
        "    out = F.avg_pool2d(out, kernel_size=7, stride=1).view(features.size(0), -1)\n",
        "    out = self.fc(out)\n",
        "    return out\n",
        "\n",
        "  def cam_out(self):\n",
        "      return self.relu_out"
      ],
      "metadata": {
        "id": "jp7rZAp2NGQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model4-ResNeXt50"
      ],
      "metadata": {
        "id": "hpPKti4WzUBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNeXt50(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(ResNeXt50, self).__init__()\n",
        "        model = models.resnext50_32x4d(pretrained=True)\n",
        "        #resnext101_32x4d = torch.hub.load('pytorch/vision:v0.10.0', 'resnext101_32x4d', pretrained=True)\n",
        "        self.num_classes = num_classes\n",
        "        #self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
        "        self.conv1 = model.conv1\n",
        "        self.bn1 = model.bn1\n",
        "        self.relu = model.relu\n",
        "        self.layer1 = model.layer1\n",
        "        self.layer2 = model.layer2\n",
        "        self.layer3 = model.layer3\n",
        "        #self.features = model.features\n",
        "        #self.avg_pool = nn.AvgPool2d((7, 7), (1, 1))\n",
        "        self.avg_pool = model.avgpool\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.conv1(input)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "OBCqKpQOsCJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 5- Wide ResNet50"
      ],
      "metadata": {
        "id": "sopqou9TzcKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WideResnet50(nn.Module):\n",
        "  def __init__(self, num_classes = 2):\n",
        "    super(WideResnet50, self).__init__()\n",
        "    model = models.wide_resnet50_2(pretrained=True)\n",
        "    self.conv1 = model.conv1\n",
        "    self.maxpool = model.maxpool\n",
        "    self.layer1 = model.layer1\n",
        "    self.layer2 = model.layer2\n",
        "    self.layer3 = model.layer3\n",
        "    self.avgpool = model.avgpool\n",
        "    self.fc = nn.Linear(1024, num_classes)\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "35Tir3-csCmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preperation"
      ],
      "metadata": {
        "id": "QGFzrCcyzio_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_training(root_path, dir, batch_size, kwargs):\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.Resize([256, 256]),\n",
        "         transforms.RandomRotation(15),\n",
        "         transforms.ColorJitter(),\n",
        "         transforms.RandomCrop(224),\n",
        "         transforms.RandomHorizontalFlip(),\n",
        "         transforms.RandomVerticalFlip(),\n",
        "         transforms.ToTensor()\n",
        "         ])\n",
        "    data = datasets.ImageFolder(root=os.path.join(root_path, dir), transform=transform)\n",
        "    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)\n",
        "    return train_loader\n",
        "\n",
        "def load_testing(root_path, dir, batch_size, kwargs):\n",
        "\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.Resize([224, 224]),\n",
        "         transforms.ToTensor()])\n",
        "    data = datasets.ImageFolder(root=os.path.join(root_path, dir), transform=transform)\n",
        "    # print(list(data.imgs))\n",
        "    names = list(map(lambda x: os.path.basename(x[0]), list(data.imgs)))\n",
        "    label = list(map(lambda x: x[1], list(data.imgs)))\n",
        "    # print(names, label)\n",
        "    # for name, label in data.imgs:\n",
        "    #     print(name, label)\n",
        "    test_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False, **kwargs)\n",
        "    return test_loader, names, label"
      ],
      "metadata": {
        "id": "4zqP7j1sC8wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and plotting functions"
      ],
      "metadata": {
        "id": "pd5Ko_Gbzn9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train(model, train_dl, val_dl, epochs=100, device='cpu'):\n",
        "\n",
        "\n",
        "    history = {} # Collects per-epoch loss and acc like Keras' fit().\n",
        "    history['loss'] = []\n",
        "    history['val_loss'] = []\n",
        "    history['acc'] = []\n",
        "    history['val_acc'] = []\n",
        "\n",
        "    start_time_sec = time.time()\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        LEARNING_RATE = max(lr * (0.1 ** (epochs // 100)), 1e-5)\n",
        "        optimizer = torch.optim.SGD([{'params': model.parameters()}], lr=LEARNING_RATE, momentum=momentum, weight_decay=l2_decay)\n",
        "\n",
        "        # --- TRAIN AND EVALUATE ON TRAINING SET -----------------------------\n",
        "        model.train()\n",
        "        train_loss         = 0.0\n",
        "        num_train_correct  = 0\n",
        "        num_train_examples = 0\n",
        "\n",
        "        for batch in train_dl:\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            x    = batch[0].to(device)\n",
        "            y    = batch[1].to(device)\n",
        "            yhat = model(x)\n",
        "            optimizer.zero_grad()\n",
        "            loss = F.nll_loss(F.log_softmax(yhat, dim=1), y)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss         += loss.data.item() * x.size(0)\n",
        "            num_train_correct  += (torch.max(yhat, 1)[1] == y).sum().item()\n",
        "            num_train_examples += x.shape[0]\n",
        "\n",
        "        train_acc   = num_train_correct / num_train_examples\n",
        "        train_loss  = train_loss / len(train_dl.dataset)\n",
        "\n",
        "\n",
        "        # --- EVALUATE ON VALIDATION SET -------------------------------------\n",
        "        model.eval()\n",
        "        val_loss       = 0.0\n",
        "        num_val_correct  = 0\n",
        "        num_val_examples = 0\n",
        "\n",
        "        for batch in val_dl:\n",
        "\n",
        "            x    = batch[0].to(device)\n",
        "            y    = batch[1].to(device)\n",
        "            yhat = model(x)\n",
        "            loss=F.nll_loss(F.log_softmax(yhat, dim=1), y, size_average=False)\n",
        "\n",
        "            val_loss         += loss.data.item() * x.size(0)\n",
        "            num_val_correct  += (torch.max(yhat, 1)[1] == y).sum().item()\n",
        "            num_val_examples += y.shape[0]\n",
        "\n",
        "        val_acc  = num_val_correct / num_val_examples\n",
        "        val_loss = val_loss / len(val_dl.dataset)\n",
        "\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "          print('Epoch %3d/%3d, train loss: %5.2f, train acc: %5.2f, val loss: %5.2f, val acc: %5.2f' % \\\n",
        "                (epoch, epochs, train_loss, train_acc, val_loss, val_acc))\n",
        "\n",
        "        history['loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['acc'].append(train_acc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "    # END OF TRAINING LOOP\n",
        "\n",
        "\n",
        "    end_time_sec       = time.time()\n",
        "    total_time_sec     = end_time_sec - start_time_sec\n",
        "    time_per_epoch_sec = total_time_sec / epochs\n",
        "    print()\n",
        "    print('Time total:     %5.2f sec' % (total_time_sec))\n",
        "    print('Time per epoch: %5.2f sec' % (time_per_epoch_sec))\n",
        "\n",
        "    return history\n",
        "\n",
        "def plot_loss(history, model_name):\n",
        "  plt.plot(history['loss'])\n",
        "  plt.plot(history['val_loss'])\n",
        "  plt.title(model_name +' Loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "def plot_accuracy(history, model_name):\n",
        "  plt.plot(history['acc'])\n",
        "  plt.plot(history['val_acc'])\n",
        "  plt.title(model_name +' Accuracy')\n",
        "  plt.ylabel('acc')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "D3f8O4K3DNuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fixing the training parameters"
      ],
      "metadata": {
        "id": "xzvm1Nwbz4JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "epochs = 20\n",
        "lr = 0.01\n",
        "momentum = 0.8\n",
        "no_cuda = False\n",
        "seed = 8\n",
        "log_interval = 10\n",
        "l2_decay = 5e-4\n",
        "random_seed = 80\n",
        "split_train_ratio=0.2\n",
        "\n",
        "path = \"drive/MyDrive/Dataset_BUSI_with_GT/\"\n",
        "source_name = \"train\"\n",
        "target_name = \"val\""
      ],
      "metadata": {
        "id": "Vf1V8KNzC-ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling GPU support"
      ],
      "metadata": {
        "id": "OQv8tMjhz7B-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuda = not no_cuda and torch.cuda.is_available()\n",
        "torch.manual_seed(seed)\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(seed)\n",
        "kwargs = {'num_workers': 4, 'pin_memory': True} if cuda else {}"
      ],
      "metadata": {
        "id": "Z72mGJSjDHhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Data Loaders"
      ],
      "metadata": {
        "id": "mL9RqQRt0BLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(os.listdir(os.path.join(path, source_name)))\n",
        "source_loader = load_training(path, source_name, batch_size, kwargs)\n",
        "target_test_loader, names, label = load_testing(path, target_name, batch_size, kwargs)\n",
        "\n",
        "len_source_dataset = len(source_loader.dataset)\n",
        "len_target_dataset = len(target_test_loader.dataset)\n",
        "len_source_loader = len(source_loader)"
      ],
      "metadata": {
        "id": "5e2QpcXxDI15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1 training"
      ],
      "metadata": {
        "id": "Ig1KGJVw0GUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_inc = InceptionV3(num_classes=num_classes)\n",
        "model_inc.cuda()\n",
        "history_inc=train(model_inc, source_loader, target_test_loader, epochs=50, device='cuda')"
      ],
      "metadata": {
        "id": "iLRpulk9DPWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2 training"
      ],
      "metadata": {
        "id": "4qjQmI1K0K_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_res=Resnet34(num_classes=num_classes)\n",
        "model_res.cuda()\n",
        "history_res=train(model_res, source_loader, target_test_loader, epochs=50, device='cuda')"
      ],
      "metadata": {
        "id": "xNdw3mQ0NwfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3 training"
      ],
      "metadata": {
        "id": "p3-ifwxf0OMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dense=Densnet121(num_classes=num_classes)\n",
        "model_dense.cuda()\n",
        "history_dense=train(model_dense, source_loader, target_test_loader, epochs=50, device='cuda')"
      ],
      "metadata": {
        "id": "uVNa658oSNTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 4 training"
      ],
      "metadata": {
        "id": "0xfzVMpn0RdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model_next=models.resnext50_32x4d(pretrained=True)\n",
        "model_next = ResNeXt50()\n",
        "model_next.cuda()\n",
        "history_next=train(model_next, source_loader, target_test_loader, epochs=50, device='cuda')"
      ],
      "metadata": {
        "id": "ekx6TvTBty33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 5 training"
      ],
      "metadata": {
        "id": "rrK8zwHV0UjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_wres = WideResnet50()\n",
        "model_wres.cuda()\n",
        "history_wres=train(model_wres, source_loader, target_test_loader, epochs=50, device='cuda')"
      ],
      "metadata": {
        "id": "zJ_LVebHvVhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the accuracy and loss curve for each"
      ],
      "metadata": {
        "id": "Fkh7wD_j0YKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracy(history_inc, 'InceptionV3')\n",
        "plot_loss(history_inc, 'InceptionV3')\n",
        "plot_accuracy(history_res, 'ResNet')\n",
        "plot_loss(history_res, 'ResNet')\n",
        "plot_accuracy(history_dense, 'DenseNet')\n",
        "plot_loss(history_dense, 'DenseNet')\n",
        "plot_accuracy(history_next, 'ResNeXt')\n",
        "plot_loss(history_next, 'ResNeXt')\n",
        "plot_accuracy(history_wres, 'Wide ResNet')\n",
        "plot_loss(history_wres, 'Wide ResNet')"
      ],
      "metadata": {
        "id": "1eyS5TjSaxTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for the ensemble network"
      ],
      "metadata": {
        "id": "wpCeUoAb0fxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def output(model, data):\n",
        "    model.eval()\n",
        "    s_output = model(data)\n",
        "    M_possibility = float(F.softmax(s_output).data.cpu().numpy()[0][1])\n",
        "    return M_possibility\n",
        "\n",
        "\n",
        "def get_result_by_model(image, model):\n",
        "    result = output(model, image)\n",
        "\n",
        "    if result >= .5:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def get_result_birads(image):\n",
        "    result = (.2)*output(model_inc, image)  + (.2)*output(model_res, image) + (.2)*output(model_dense, image) + (.2)*output(model_next, image) + (.2)*output(model_wres, image)\n",
        "    if result >= 0.5:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def get_result_tirads(image):\n",
        "    result = (.2)*output(model_inc, image)  + (.2)*output(model_res, image) + (.2)*output(model_dense, image) + (.2)*output(model_next, image) + (.2)*output(model_wres, image)\n",
        "    if result >= 0.35:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def get_result_birads_v2(image):\n",
        "    result = (.25)*output(model_inc, image)  + (.25)*output(model_res, image) + (.25)*output(model_next, image) + (.25)*output(model_wres, image)\n",
        "    if result >= 0.5:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def get_pytorch_image(name):\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.Resize([224, 224]),\n",
        "         transforms.ToTensor()])\n",
        "    image = Image.open(name)\n",
        "    image = image.convert(\"RGB\")\n",
        "    image = transform(image)\n",
        "    image = image.unsqueeze(0)\n",
        "    image = image.cuda()\n",
        "    return image"
      ],
      "metadata": {
        "id": "vUKvt7dbeszI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading test data"
      ],
      "metadata": {
        "id": "WRRvf3ya0ov-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_load, name1, label1 = load_testing(path, 'test', batch_size, kwargs)"
      ],
      "metadata": {
        "id": "gGRhcRAwfHOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance of ensemble 2"
      ],
      "metadata": {
        "id": "nEVPR0Fi0tUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_label=[]\n",
        "for n,l in zip(name1,label1):\n",
        "  if l==0:\n",
        "    img=path+'test/benign/'+n;\n",
        "  else:\n",
        "    img=path+'test/malignant/'+n;\n",
        "  img=get_pytorch_image(img)\n",
        "  temp=get_result_birads_v2(img)\n",
        "  pred_label.append(temp)\n",
        "\n",
        "from sklearn.metrics import accuracy_score,average_precision_score, f1_score,recall_score, precision_score\n",
        "acc=accuracy_score(label1,pred_label)\n",
        "f1=f1_score(label1,pred_label)\n",
        "re=recall_score(label1,pred_label)\n",
        "pre=precision_score(label1,pred_label)\n",
        "\n",
        "print(acc)\n",
        "print(f1)\n",
        "print(re)\n",
        "print(pre)"
      ],
      "metadata": {
        "id": "40LHUK6HfMOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "performance of ensemble 1"
      ],
      "metadata": {
        "id": "zmaata7v00B0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_label=[]\n",
        "for n,l in zip(name1,label1):\n",
        "  if l==0:\n",
        "    img=path+'test/benign/'+n;\n",
        "  else:\n",
        "    img=path+'test/malignant/'+n;\n",
        "  img=get_pytorch_image(img)\n",
        "  temp=get_result_birads(img)\n",
        "  pred_label.append(temp)\n",
        "\n",
        "from sklearn.metrics import accuracy_score,average_precision_score, f1_score,recall_score, precision_score\n",
        "acc=accuracy_score(label1,pred_label)\n",
        "f1=f1_score(label1,pred_label)\n",
        "re=recall_score(label1,pred_label)\n",
        "pre=precision_score(label1,pred_label)\n",
        "\n",
        "print(acc)\n",
        "print(f1)\n",
        "print(re)\n",
        "print(pre)"
      ],
      "metadata": {
        "id": "xdc6hqMaxodY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance of model 2"
      ],
      "metadata": {
        "id": "nyqJfXw506jb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_label=[]\n",
        "for n,l in zip(name1,label1):\n",
        "  if l==0:\n",
        "    img=path+'test/benign/'+n;\n",
        "  else:\n",
        "    img=path+'test/malignant/'+n;\n",
        "  img=get_pytorch_image(img)\n",
        "  temp=get_result_by_model(img, model_res)\n",
        "  pred_label.append(temp)\n",
        "\n",
        "from sklearn.metrics import accuracy_score,average_precision_score, f1_score,recall_score, precision_score\n",
        "acc=accuracy_score(label1,pred_label)\n",
        "f1=f1_score(label1,pred_label)\n",
        "re=recall_score(label1,pred_label)\n",
        "pre=precision_score(label1,pred_label)\n",
        "\n",
        "print(acc)\n",
        "print(f1)\n",
        "print(re)\n",
        "print(pre)"
      ],
      "metadata": {
        "id": "d7Yd33uQf573"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance of model 3"
      ],
      "metadata": {
        "id": "0Y8a3pfY1Cse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_label=[]\n",
        "for n,l in zip(name1,label1):\n",
        "  if l==0:\n",
        "    img=path+'test/benign/'+n;\n",
        "  else:\n",
        "    img=path+'test/malignant/'+n;\n",
        "  img=get_pytorch_image(img)\n",
        "  temp=get_result_by_model(img, model_dense)\n",
        "  pred_label.append(temp)\n",
        "\n",
        "from sklearn.metrics import accuracy_score,average_precision_score, f1_score,recall_score, precision_score\n",
        "acc=accuracy_score(label1,pred_label)\n",
        "f1=f1_score(label1,pred_label)\n",
        "re=recall_score(label1,pred_label)\n",
        "pre=precision_score(label1,pred_label)\n",
        "\n",
        "print(acc)\n",
        "print(f1)\n",
        "print(re)\n",
        "print(pre)"
      ],
      "metadata": {
        "id": "J0FAd6fFyd33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance of model 1"
      ],
      "metadata": {
        "id": "pTTPEs4-1Fgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_label=[]\n",
        "for n,l in zip(name1,label1):\n",
        "  if l==0:\n",
        "    img=path+'test/benign/'+n;\n",
        "  else:\n",
        "    img=path+'test/malignant/'+n;\n",
        "  img=get_pytorch_image(img)\n",
        "  temp=get_result_by_model(img, model_inc)\n",
        "  pred_label.append(temp)\n",
        "\n",
        "from sklearn.metrics import accuracy_score,average_precision_score, f1_score,recall_score, precision_score\n",
        "acc=accuracy_score(label1,pred_label)\n",
        "f1=f1_score(label1,pred_label)\n",
        "re=recall_score(label1,pred_label)\n",
        "pre=precision_score(label1,pred_label)\n",
        "\n",
        "print(acc)\n",
        "print(f1)\n",
        "print(re)\n",
        "print(pre)"
      ],
      "metadata": {
        "id": "EdpK97sgyeEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance of model 4"
      ],
      "metadata": {
        "id": "Mnyz55ao1Ia6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_label=[]\n",
        "for n,l in zip(name1,label1):\n",
        "  if l==0:\n",
        "    img=path+'test/benign/'+n;\n",
        "  else:\n",
        "    img=path+'test/malignant/'+n;\n",
        "  img=get_pytorch_image(img)\n",
        "  temp=get_result_by_model(img, model_next)\n",
        "  pred_label.append(temp)\n",
        "\n",
        "from sklearn.metrics import accuracy_score,average_precision_score, f1_score,recall_score, precision_score\n",
        "acc=accuracy_score(label1,pred_label)\n",
        "f1=f1_score(label1,pred_label)\n",
        "re=recall_score(label1,pred_label)\n",
        "pre=precision_score(label1,pred_label)\n",
        "\n",
        "print(acc)\n",
        "print(f1)\n",
        "print(re)\n",
        "print(pre)"
      ],
      "metadata": {
        "id": "JTl59GbayeRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance of model 5"
      ],
      "metadata": {
        "id": "DHJ5reVg1L_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_label=[]\n",
        "for n,l in zip(name1,label1):\n",
        "  if l==0:\n",
        "    img=path+'test/benign/'+n;\n",
        "  else:\n",
        "    img=path+'test/malignant/'+n;\n",
        "  img=get_pytorch_image(img)\n",
        "  temp=get_result_by_model(img, model_wres)\n",
        "  pred_label.append(temp)\n",
        "\n",
        "from sklearn.metrics import accuracy_score,average_precision_score, f1_score,recall_score, precision_score\n",
        "acc=accuracy_score(label1,pred_label)\n",
        "f1=f1_score(label1,pred_label)\n",
        "re=recall_score(label1,pred_label)\n",
        "pre=precision_score(label1,pred_label)\n",
        "\n",
        "print(acc)\n",
        "print(f1)\n",
        "print(re)\n",
        "print(pre)"
      ],
      "metadata": {
        "id": "vrxPPhCnyebT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}